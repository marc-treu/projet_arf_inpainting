{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet ARF : inpainting \n",
    "##### TREÜ Marc ; KARMIM Yannis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préambule : régression linéaire, régression ridge et LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression,Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def load_usps(filename):\n",
    "    with open(filename,\"r\") as f:\n",
    "        f.readline()\n",
    "        data =[ [float(x) for x in l.split()] for l in f if len(l.split())>2]\n",
    "    tmp = np.array(data)\n",
    "    return tmp[:,1:],tmp[:,0].astype(int)\n",
    "\n",
    "\n",
    "# Chargement des données USPS. \n",
    "\n",
    "trainX, trainY = load_usps('data/USPS_train.txt')\n",
    "testX, testY = load_usps('data/USPS_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_regression(n1,n2,dataX,dataY):\n",
    "    \n",
    "    \"\"\"Compare deux classes représentant les nombres n1 et n2\n",
    "    en utilisant une régression linéaire .\"\"\"\n",
    "\n",
    "    indice_classe = np.where(np.in1d(dataY, [n1,n2]))\n",
    "    X = dataX[indice_classe]\n",
    "    Y = np.where(dataY[indice_classe] == n1, 1, -1)\n",
    "\n",
    "    return LinearRegression(normalize=True).fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des classes : \n",
    "n1 = 1\n",
    "n2 = 7\n",
    "\n",
    "reg = fit_linear_regression(n1,n2,trainX,trainY)\n",
    "\n",
    "indice_classe = np.where(np.in1d(testY, [n1,n2]))\n",
    "X_test = testX[indice_classe]\n",
    "Y_test = np.where(testY[indice_classe] == n1, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score calculer avec le coeficient de determination R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.4150241635465626e+19"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score calculé avec la methode plug-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708029197080292"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sign(reg.predict(X_test)) == Y_test) / len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plugin_score(models, X_test, Y_test):\n",
    "    return np.sum(np.sign(models.predict(X_test)) == Y_test) / len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression ( sans Cross Val ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score avec la ridge regression 0.9878345498783455\n"
     ]
    }
   ],
   "source": [
    "def fit_ridge_regression(n1,n2,dataX,dataY,alpha=1.0):\n",
    "    \"\"\"Compare deux classes représentant les nombres n1 et n2\n",
    "    en utilisant une Ridge Regression.\"\"\"\n",
    "    \n",
    "    indice_classe = np.where(np.in1d(dataY, [n1,n2]))\n",
    "    X = dataX[indice_classe]\n",
    "    Y = np.where(dataY[indice_classe] == n1, 1, -1)\n",
    "\n",
    "    return Ridge(alpha=alpha).fit(X,Y)\n",
    "\n",
    "ridge = fit_ridge_regression(n1,n2,trainX,trainY,alpha=1.0)\n",
    "print(\"score avec la ridge regression :\", plugin_score(ridge, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression ( avec Cross Val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur alpha trouvé par Cross Validation :  20.0\n",
      "score avec la ridge regression + cross validation 0.9854014598540146\n"
     ]
    }
   ],
   "source": [
    "def fit_ridge_regressionCV(n1,n2,dataX,dataY,nb_cv = 10, verbose=False):\n",
    "    \"\"\"Compare deux classes représentant les nombres n1 et n2\n",
    "    en utilisant une Ridge Regression avec Cross Val.\"\"\"\n",
    "    \n",
    "    indice_classe = np.where(np.in1d(dataY, [n1,n2]))\n",
    "    X = dataX[indice_classe]\n",
    "    Y = np.where(dataY[indice_classe] == n1, 1, -1)\n",
    "    \n",
    "    clf = RidgeCV(alphas=(0.1, 1, 5, 10, 20), cv = nb_cv)\n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Meilleur alpha trouvé par Cross Validation : \",clf.alpha_)\n",
    "    \n",
    "    return clf \n",
    "\n",
    "ridgeCV = fit_ridge_regressionCV(n1, n2, trainX, trainY, verbose=True)\n",
    "print(\"score avec la ridge regression + cross validation :\",plugin_score(ridgeCV, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score avec lasso regression 0.9635036496350365\n"
     ]
    }
   ],
   "source": [
    "def fit_LASSO(n1,n2,dataX,dataY,alpha = 0.001):\n",
    "    \"\"\"Compare deux classes représentant les nombres n1 et n2\n",
    "    en utilisant une Ridge Regression avec Cross Val.\"\"\"\n",
    "    \n",
    "    indice_classe = np.where(np.in1d(dataY, [n1,n2]))\n",
    "    X = dataX[indice_classe]\n",
    "    Y = np.where(dataY[indice_classe] == n1, 1, -1)\n",
    "    clf = Lasso(alpha = alpha)\n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    return clf \n",
    "\n",
    "lasso = fit_LASSO(n1,n2,trainX,trainY,alpha=0.1)\n",
    "print(\"score avec lasso regression :\", plugin_score(lasso, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur alpha trouvé par Cross Validation :  0.0014878791090701493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9829683698296837"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_LASSO_CV(n1,n2,dataX,dataY,nb_cv = 10, verbose=False):\n",
    "    \"\"\"Compare deux classes représentant les nombres n1 et n2\n",
    "    en utilisant une Ridge Regression avec Cross Val.\"\"\"\n",
    "    \n",
    "    indice_classe = np.where(np.in1d(dataY, [n1,n2]))\n",
    "    X = dataX[indice_classe]\n",
    "    Y = np.where(dataY[indice_classe] == n1, 1, -1)\n",
    "    \n",
    "    clf = LassoCV(cv = nb_cv)\n",
    "    clf.fit(X,Y)\n",
    "    if verbose:\n",
    "        print(\"Meilleur alpha trouvé par Cross Validation : \",clf.alpha_)\n",
    "    \n",
    "    return clf \n",
    "\n",
    "lassoCV = fit_LASSO_CV(n1, n2, trainX, trainY, verbose=True)\n",
    "plugin_score(lassoCV, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def calcule_all_result(trainX, trainY, testX, testY):\n",
    "    \n",
    "    # Combinaison de tous les classifieur classe i vs classe j : [(1, 2), (1, 3), ...]\n",
    "    combinaison = [i for i in itertools.combinations([(j) for j in range(10)], 2)]\n",
    "    \n",
    "    # On fit les 5 models pour chaque classe i vs classe j\n",
    "    models_regression = [fit_linear_regression(n[0], n[1], trainX, trainY) for n in combinaison]\n",
    "    \n",
    "    models_ridge = [fit_ridge_regression(n[0], n[1], trainX, trainY) for n in combinaison]\n",
    "    models_ridgeCV = [fit_ridge_regressionCV(n[0], n[1], trainX, trainY) for n in combinaison]\n",
    "    \n",
    "    models_lasso = [fit_LASSO(n[0],n[1], trainX, trainY) for n in combinaison]\n",
    "    models_lassoCV = [fit_LASSO_CV(n[0],n[1], trainX, trainY) for n in combinaison]\n",
    "    \n",
    "    models = [models_regression, models_ridge, models_ridgeCV, models_lasso, models_lassoCV]\n",
    "    \n",
    "    score_models_regression = []\n",
    "    score_models_ridge = []\n",
    "    score_models_ridgeCV = []\n",
    "    score_models_lasso = []\n",
    "    score_models_lassoCV = [] \n",
    "    \n",
    "    for n in range(len(combinaison)):\n",
    "        n1, n2 = combinaison[n]\n",
    "        indice_classe = np.where(np.in1d(testY, [n1,n2]))\n",
    "        X = testX[indice_classe]\n",
    "        Y = np.where(testY[indice_classe] == n1, 1, -1)\n",
    "        \n",
    "        score_models_regression.append(plugin_score(models_regression[n], X, Y))\n",
    "        score_models_ridge.append(plugin_score(models_ridge[n], X, Y))\n",
    "        score_models_ridgeCV.append(plugin_score(models_ridgeCV[n], X, Y))\n",
    "        score_models_lasso.append(plugin_score(models_lasso[n], X, Y))\n",
    "        score_models_lassoCV.append(plugin_score(models_lassoCV[n], X, Y))\n",
    "\n",
    "    scores = [score_models_regression, score_models_ridge, score_models_ridgeCV, score_models_lasso, score_models_lassoCV] \n",
    "    \n",
    "    return models, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, scores = calcule_all_result(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcule_w_moyen(liste_modele):\n",
    "    return sum(sum(abs(w) for w in liste_modele[i].coef_) / 256 for i in range(len(liste_modele))) / len(liste_modele)\n",
    "\n",
    "def calcule_w_var(liste_modele):\n",
    "    return np.var([[w for w in liste_modele[i].coef_ ] for i in range(len(liste_modele))])\n",
    "    \n",
    "def calcule_nombre_w_null(liste_modele):\n",
    "    return sum(len(np.where(liste_modele[i].coef_ == 0)[0]) for i in range(len(liste_modele))) / len(liste_modele)\n",
    "\n",
    "def calcule_score_moy(liste_score):\n",
    "    return sum(liste_score) / len(liste_score)\n",
    "    \n",
    "def calcule_all(modeles, scores):\n",
    "    return calcule_score_moy(scores), calcule_w_moyen(modeles), calcule_w_var(modeles), calcule_nombre_w_null(modeles)\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_reg = calcule_all(models[0], scores[0])\n",
    "resultat_ridge = calcule_all(models[1], scores[1])\n",
    "resultat_ridgeCV = calcule_all(models[2], scores[2])\n",
    "resultat_lasso = calcule_all(models[3], scores[3])\n",
    "resultat_lassoCV = calcule_all(models[4], scores[4])\n",
    "\n",
    "resultat_all = [calcule_all(models[i], scores[i]) for i in range(5)]\n",
    "\n",
    "def print_resultat(resultat):\n",
    "    nom_reg = {0:\"Regression simplement avec MSE\", 1:\"Regression avec regularisation l2 (Ridge)\", 2:\"Regression avec regularisation l2 + cross validation\"\n",
    "    ,3:\"Regression avec regularisation l1 (Lasso)\",4:\"Regression avec regularisation l1 (Lasso) + cross validation\"}\n",
    "    \n",
    "    for i in range(5):\n",
    "        print(nom_reg[i],\":\\n\\t\\tscore moyenne =\", resultat[i][0], \"\\n\\t\\tpoid moyen des w =\", resultat[i][1]\n",
    "              , \"\\n\\t\\tvariance moyenne des w =\", resultat[i][2], \"\\n\\t\\tnombre moyen de w a 0 =\", resultat[i][3], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression simplement avec MSE :\n",
      "\t\tscore moyenne = 0.9726377952540973 \n",
      "\t\tpoid moyen des w = 554842134089.6156 \n",
      "\t\tvariance moyenne des w = 8.415495716396342e+26 \n",
      "\t\tnombre moyen de w a 0 = 0.37777777777777777 \n",
      "\n",
      "Regression avec regularisation l2 (Ridge) :\n",
      "\t\tscore moyenne = 0.9775118888513816 \n",
      "\t\tpoid moyen des w = 0.05697677217882317 \n",
      "\t\tvariance moyenne des w = 0.006887798552883184 \n",
      "\t\tnombre moyen de w a 0 = 1.5555555555555556 \n",
      "\n",
      "Regression avec regularisation l2 + cross validation :\n",
      "\t\tscore moyenne = 0.9794803574409355 \n",
      "\t\tpoid moyen des w = 0.02928553188640165 \n",
      "\t\tvariance moyenne des w = 0.0015506889223157704 \n",
      "\t\tnombre moyen de w a 0 = 1.5555555555555556 \n",
      "\n",
      "Regression avec regularisation l1 (Lasso) :\n",
      "\t\tscore moyenne = 0.9786068623246679 \n",
      "\t\tpoid moyen des w = 0.022131600613787345 \n",
      "\t\tvariance moyenne des w = 0.001833394941678783 \n",
      "\t\tnombre moyen de w a 0 = 110.97777777777777 \n",
      "\n",
      "Regression avec regularisation l1 (Lasso) + cross validation :\n",
      "\t\tscore moyenne = 0.9786179799146486 \n",
      "\t\tpoid moyen des w = 0.015826092691775505 \n",
      "\t\tvariance moyenne des w = 0.001109646689007724 \n",
      "\t\tnombre moyen de w a 0 = 143.4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_resultat(resultat_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les modèles ont des performances similaire, c'est à dire au alentour de 97% de bonne classification,\n",
    "mais c'est avec les poids de W apris que la différence est la plus flagrante. Alors que l'on a un W moyenne a 500 millard avec une variance en 10^26 pour la regression sans pénalisation. On tombe à un W moyen inferieur a 0.1 et une variance inferieur a 0.01 pour les normes L1 et L2.\n",
    "\n",
    "Aussi, l'avantage pricipal de la regularisation Lasso par rapport à Ridge est le nombre de composante W qui devienne nulle, ainsi on a en moyenne 143 W qui devienne egale à 0, sur nos 256 dimension cela represente près de 55% pixels qu'on ne prend plus en consideration pour la classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO et Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
